# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iqe7SY1cu91wELCRkjoJQnKFhymeBPP9
"""

import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras.applications.densenet import preprocess_input
from xgboost import XGBClassifier
import joblib
import shap
import matplotlib.pyplot as plt
from PIL import Image
import io

# -----------------------------------------------------------------------------
# KONFIGURASI HALAMAN & CACHING
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="Rice Leaf Disease Detector",
    page_icon="üåæ",
    layout="wide"
)

# Cache Model agar tidak dimuat ulang setiap klik
@st.cache_resource
def load_models():
    # 1. Load DenseNet201 (Feature Extractor)
    # Kita menggunakan bobot imagenet dan pooling avg seperti di notebook
    feature_extractor = DenseNet201(
        weights="imagenet",
        include_top=False,
        pooling="avg",
        input_shape=(224, 224, 3)
    )

    # 2. Load XGBoost (Classifier)
    # Pastikan file 'xgb_best_model.pkl' ada di direktori yang sama
    try:
        classifier = joblib.load("xgb_best_model.pkl")
    except FileNotFoundError:
        st.error("File 'xgb_best_model.pkl' tidak ditemukan. Pastikan Anda sudah melatih dan menyimpan model.")
        classifier = None

    return feature_extractor, classifier

# Preprocessing Gambar
def process_image(img_file):
    img = Image.open(img_file).convert("RGB")
    img = img.resize((224, 224))
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)
    # Preprocessing bawaan DenseNet
    img_array = preprocess_input(img_array.astype(np.float32))
    return img_array

# Ekstraksi Fitur
def extract_features(model, img_array):
    features = model.predict(img_array)
    return features

# Inisialisasi Session State untuk menyimpan data antar halaman
if 'uploaded_data' not in st.session_state:
    st.session_state['uploaded_data'] = None
if 'features' not in st.session_state:
    st.session_state['features'] = None
if 'predictions' not in st.session_state:
    st.session_state['predictions'] = None
if 'file_names' not in st.session_state:
    st.session_state['file_names'] = []

# Label Kelas (Sesuai urutan LabelEncoder di notebook: BrownSpot, Healthy, Hispa, LeafBlast)
CLASSES = ["BrownSpot", "Healthy", "Hispa", "LeafBlast"]

# Load Models
feature_extractor, classifier = load_models()

# -----------------------------------------------------------------------------
# SIDEBAR NAVIGATION
# -----------------------------------------------------------------------------
st.sidebar.title("Navigasi")
menu = ["Home", "Upload & Preview", "Run Model", "Explainability", "Download"]
choice = st.sidebar.radio("Pergi ke", menu)

# -----------------------------------------------------------------------------
# HALAMAN 1: HOME
# -----------------------------------------------------------------------------
if choice == "Home":
    st.title("üåæ Rice Leaf Disease Detection System")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Rice_fields_in_Bali.jpg/800px-Rice_fields_in_Bali.jpg", use_column_width=True)

    st.markdown("""
    ### Deskripsi Proyek
    Aplikasi ini dikembangkan untuk mendeteksi penyakit pada daun padi menggunakan metode **Hybrid Deep Learning & Machine Learning**.

    **Metodologi:**
    1.  **Feature Extraction**: Menggunakan **DenseNet201** (Transfer Learning) untuk mengekstrak fitur visual kompleks dari citra daun.
    2.  **Classification**: Menggunakan **XGBoost** (eXtreme Gradient Boosting) yang telah dioptimasi hyperparameternya untuk klasifikasi akhir.

    **Jenis Penyakit yang Dideteksi:**
    * **BrownSpot** (Bercak Coklat)
    * **Hispa** (Hama Putih)
    * **LeafBlast** (Penyakit Blas)
    * **Healthy** (Sehat)

    **Dataset:**
    Bersumber dari Kaggle (*Rice Leaf Images*), terdiri dari ribuan citra yang terbagi menjadi 4 kelas tersebut.
    """)

# -----------------------------------------------------------------------------
# HALAMAN 2: UPLOAD & PREVIEW
# -----------------------------------------------------------------------------
elif choice == "Upload & Preview":
    st.title("üìÇ Upload & Preview Data")

    st.info("Anda dapat mengunggah **Citra Tunggal/Banyak** (untuk diproses otomatis) atau **File CSV** (berisi fitur ekstraksi jika ada).")

    tab1, tab2 = st.tabs(["Upload Gambar", "Upload CSV Fitur"])

    # --- TAB 1: UPLOAD GAMBAR ---
    with tab1:
        uploaded_files = st.file_uploader("Upload Citra Daun Padi (JPG/PNG)", type=["jpg", "png", "jpeg"], accept_multiple_files=True)

        if uploaded_files:
            st.session_state['file_names'] = [f.name for f in uploaded_files]

            # Preview dalam Grid
            st.subheader("Preview Citra")
            cols = st.columns(4)
            for i, file in enumerate(uploaded_files):
                img = Image.open(file)
                cols[i % 4].image(img, caption=file.name, use_column_width=True)

            # Tombol Proses Ekstraksi Fitur
            if st.button("Proses & Ekstrak Fitur (DenseNet201)"):
                with st.spinner('Sedang mengekstrak fitur dengan DenseNet201...'):
                    all_features = []
                    for file in uploaded_files:
                        img_arr = process_image(file)
                        feats = extract_features(feature_extractor, img_arr)
                        all_features.append(feats[0])

                    # Simpan ke session state sebagai DataFrame
                    df_features = pd.DataFrame(all_features)
                    st.session_state['features'] = df_features
                    st.session_state['uploaded_data'] = "Images"
                    st.success(f"Berhasil mengekstrak fitur dari {len(uploaded_files)} citra! Fitur dimensi: {df_features.shape}")

    # --- TAB 2: UPLOAD CSV ---
    with tab2:
        uploaded_csv = st.file_uploader("Upload CSV (Fitur Ekstraksi)", type=["csv"])
        if uploaded_csv:
            df = pd.read_csv(uploaded_csv)
            st.dataframe(df.head())
            st.session_state['features'] = df
            st.session_state['uploaded_data'] = "CSV"
            st.session_state['file_names'] = [f"Sample_{i}" for i in range(len(df))]
            st.success(f"CSV berhasil dimuat. Dimensi: {df.shape}")

# -----------------------------------------------------------------------------
# HALAMAN 3: RUN MODEL
# -----------------------------------------------------------------------------
elif choice == "Run Model":
    st.title("üöÄ Run Classification Model")

    if st.session_state['features'] is None:
        st.warning("Silakan upload data (Gambar/CSV) terlebih dahulu di menu 'Upload & Preview'.")
    else:
        st.write(f"**Data Siap:** {len(st.session_state['features'])} sampel.")

        model_option = st.selectbox("Pilih Model", ["XGBoost (Tuned)"])

        if st.button("Predict"):
            if classifier:
                with st.spinner('Sedang melakukan prediksi...'):
                    # Prediksi menggunakan XGBoost
                    X = st.session_state['features'].values
                    probs = classifier.predict_proba(X)
                    preds = classifier.predict(X)

                    # Konversi Label Encode (0,1,2,3) ke Nama Kelas
                    pred_labels = [CLASSES[p] for p in preds]
                    confidence = [np.max(prob) for prob in probs]

                    # Buat DataFrame Hasil
                    results_df = pd.DataFrame({
                        "File Name": st.session_state['file_names'],
                        "Prediction": pred_labels,
                        "Confidence": confidence
                    })

                    # Tambahkan probabilitas per kelas
                    for i, cls in enumerate(CLASSES):
                        results_df[f"Prob_{cls}"] = probs[:, i]

                    st.session_state['predictions'] = results_df

                    # Tampilkan Tabel Hasil
                    st.subheader("Hasil Prediksi")
                    st.dataframe(results_df.style.highlight_max(axis=0))

                    # Tampilkan Metrics & Confusion Matrix (Jika ada Ground Truth)
                    st.divider()
                    st.markdown("### Evaluasi (Opsional)")
                    st.info("Karena ini data baru, 'Ground Truth' tidak diketahui. Masukkan label asli manual di bawah jika ingin menghitung Confusion Matrix.")

                    # Input Manual untuk Demo Evaluasi
                    with st.expander("Input Ground Truth untuk Menghitung Metrics"):
                        true_labels_idx = []
                        cols = st.columns(2)
                        for i, name in enumerate(st.session_state['file_names']):
                            # Default ke prediksi agar cepat
                            lbl = cols[i % 2].selectbox(f"Label Asli: {name}", CLASSES, index=CLASSES.index(pred_labels[i]), key=f"label_{i}")
                            true_labels_idx.append(CLASSES.index(lbl))

                        if st.button("Hitung Confusion Matrix"):
                            from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
                            import seaborn as sns

                            acc = accuracy_score(true_labels_idx, preds)
                            st.metric("Accuracy", f"{acc:.2%}")

                            cm = confusion_matrix(true_labels_idx, preds)
                            fig, ax = plt.subplots()
                            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)
                            plt.xlabel("Predicted")
                            plt.ylabel("Actual")
                            st.pyplot(fig)

# -----------------------------------------------------------------------------
# HALAMAN 4: EXPLAINABILITY (SHAP)
# -----------------------------------------------------------------------------
elif choice == "Explainability":
    st.title("üîç Explainability (SHAP)")
    st.markdown("Menganalisis fitur mana dari DenseNet201 yang paling berpengaruh terhadap keputusan XGBoost.")

    if st.session_state['features'] is None or classifier is None:
        st.warning("Silakan upload data dan pastikan model dimuat.")
    else:
        # Pilih sampel untuk dijelaskan
        sample_id = st.selectbox("Pilih Sampel untuk Dijelaskan", st.session_state['file_names'])
        idx = st.session_state['file_names'].index(sample_id)

        if st.button("Generate SHAP Explanation"):
            with st.spinner('Menghitung SHAP values (ini mungkin memakan waktu)...'):
                # Membuat Explainer XGBoost
                # Menggunakan TreeExplainer karena XGBoost berbasis Tree
                explainer = shap.TreeExplainer(classifier)

                # Hitung SHAP values untuk sampel yang dipilih (Harus dalam bentuk matriks 2D)
                X_sample = st.session_state['features'].iloc[[idx]]
                shap_values = explainer.shap_values(X_sample)

                # Visualisasi
                st.subheader(f"Kontribusi Fitur untuk Prediksi: {sample_id}")
                st.write(f"Prediksi Model: **{st.session_state['predictions'].iloc[idx]['Prediction']}**")

                # Summary Plot (Bar) untuk satu sampel
                # Karena Multiclass, shap_values adalah list array (satu per kelas). Kita ambil kelas prediksi.
                pred_class_idx = CLASSES.index(st.session_state['predictions'].iloc[idx]['Prediction'])

                fig, ax = plt.subplots()
                # shap_values[pred_class_idx] untuk kelas yang diprediksi
                shap.summary_plot(shap_values[pred_class_idx], X_sample, plot_type="bar", feature_names=[f"Feature_{i}" for i in range(1920)], show=False)
                st.pyplot(fig)

                st.info("""
                **Catatan:** Fitur yang ditampilkan (misal: `Feature_1024`) adalah fitur abstrak hasil ekstraksi DenseNet201.
                Bar yang lebih panjang menunjukkan pengaruh yang lebih besar terhadap keputusan model untuk kelas tersebut.
                """)

# -----------------------------------------------------------------------------
# HALAMAN 5: DOWNLOAD
# -----------------------------------------------------------------------------
elif choice == "Download":
    st.title("üì• Download Results")

    if st.session_state['predictions'] is None:
        st.warning("Belum ada hasil prediksi untuk diunduh. Silakan jalankan model terlebih dahulu.")
    else:
        st.success("Hasil prediksi siap diunduh.")

        # Konversi DataFrame ke CSV
        csv = st.session_state['predictions'].to_csv(index=False).encode('utf-8')

        st.download_button(
            label="Download Predictions as CSV",
            data=csv,
            file_name='rice_leaf_predictions.csv',
            mime='text/csv',
        )

        st.dataframe(st.session_state['predictions'])